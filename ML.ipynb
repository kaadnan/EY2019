{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point, LinearRing, box\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('df_train')\n",
    "df_test = pd.read_pickle('df_test')\n",
    "x_train_df_1 = pd.read_pickle('new_x_train_df')\n",
    "x_test_df_1 = pd.read_pickle('new_x_test_df')\n",
    "x_train_df = pd.read_pickle('x_train_df_2')\n",
    "x_test_df = pd.read_pickle('x_test_df_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = x_train_df.sort_values('hash',ascending=True)\n",
    "x_test_df = x_test_df.sort_values('hash',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.merge(x_train_df, x_train_df_1, on='hash')\n",
    "x_test_df = pd.merge(x_test_df, x_test_df_1, on='hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_df.shape, x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x_entry = min(min(df_train.x_entry.describe()['min'], df_test.x_entry.describe()['min']),\n",
    "                  df_train.x_exit.describe()['min'])\n",
    "min_y_entry = min(min(df_train.y_entry.describe()['min'], df_test.y_entry.describe()['min']),\n",
    "                  df_train.y_exit.describe()['min'])\n",
    "max_x_entry = max(max(df_train.x_entry.describe()['max'], df_test.x_entry.describe()['max']),\n",
    "                  df_train.x_exit.describe()['max'])\n",
    "max_y_entry = max(max(df_train.y_entry.describe()['max'], df_test.y_entry.describe()['max']),\n",
    "                  df_train.y_exit.describe()['max'])\n",
    "print(min_x_entry, max_x_entry, min_y_entry, max_y_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map():\n",
    "    rect_all = patches.Rectangle((3740998.35481912, -19042656.658487003), (3777099.2656833767 - 3740998.35481912),\n",
    "                             (- 19382914.9809002 + 19042656.658487003),\n",
    "                             linewidth=1,edgecolor='g',fill = False,hatch = '\\\\\\\\\\\\', label = 'city')\n",
    "    city = plt.gca().add_patch(rect_all)\n",
    "    rect_city = patches.Rectangle((3750901.5068, -19208905.6133), (3770901.5068 - 3750901.5068),\n",
    "                             (- 19268905.6133 + 19208905.6133),\n",
    "                             linewidth=1,edgecolor='r',fill = False,hatch = '//////', label = 'city center')\n",
    "    city_center = plt.gca().add_patch(rect_city)\n",
    "    plt.legend(handles=[city, city_center])\n",
    "    plt.grid(True)\n",
    "#     plt.xlim(min_x_entry, max_x_entry)\n",
    "    plt.ylim(min_y_entry, max_y_entry)\n",
    "    plt.xlim(3740000, 3780000)\n",
    "    plt.ylim(-19000000, - 19400000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(x,y):\n",
    "    n1 = -1\n",
    "    n2 = -1\n",
    "    if(~np.isnan(x) and ~np.isnan(y)):\n",
    "        if(x >= 3740000.0000000000 and x < 3745000.0000000000):\n",
    "            n1 = 1\n",
    "        elif(x >= 3745000.0000000000 and x < 3750000.0000000000):\n",
    "            n1 = 2\n",
    "        elif(x >= 3750000.0000000000 and x < 3755000.0000000000):\n",
    "            n1 = 3\n",
    "        elif(x >= 3755000.0000000000 and x < 3760000.0000000000):\n",
    "            n1 = 4\n",
    "        elif(x >= 3760000.0000000000 and x < 3765000.0000000000):\n",
    "            n1 = 5\n",
    "        elif(x >= 3765000.0000000000 and x < 3770000.0000000000):\n",
    "            n1 = 6\n",
    "        elif(x >= 3770000.0000000000 and x < 3775000.0000000000):\n",
    "            n1 = 7\n",
    "        else:\n",
    "            n1 = 8\n",
    "\n",
    "        if(y >= -19400000.0000000000 and y < -19350000.0000000000):\n",
    "            n2 = 8\n",
    "        elif(y >= -19350000.0000000000 and y < -19300000.0000000000):\n",
    "            n2 = 7\n",
    "        elif(y >= -19300000.0000000000 and y < -19250000.0000000000):\n",
    "            n2 = 6\n",
    "        elif(y >= -19250000.0000000000 and y < -19200000.0000000000):\n",
    "            n2 = 5\n",
    "        elif(y >= -19200000.0000000000 and y < -19150000.0000000000):\n",
    "            n2 = 4\n",
    "        elif(y >= -19150000.0000000000 and y < -19100000.0000000000):\n",
    "            n2 = 3\n",
    "        elif(y >= -19100000.0000000000 and y < -19050000.0000000000):\n",
    "            n2 = 2\n",
    "        else:\n",
    "            n2 = 1\n",
    "    \n",
    "        return (n2-1)*8 + n1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['distance'] = df_test.apply(lambda row: Point(row['x_entry'],row['y_entry']).\n",
    "                                      distance(Point(row['x_exit'],row['y_exit'])) if ~np.isnan(row['x_exit'])\n",
    "                                     else np.nan, axis=1)\n",
    "df_test['velocity'] = df_test.apply(lambda row: (row['distance']/row['duration'])\n",
    "                                      if (row['duration']!= 0.0 and ~np.isnan(row['x_exit'])) else 0.0, axis=1)\n",
    "df_train['entry_box'] = df_train.apply(lambda row: get_box(row['x_entry'], row['y_entry']) , axis=1)\n",
    "df_train['exit_box'] = df_train.apply(lambda row: get_box(row['x_exit'], row['y_exit']) , axis=1)\n",
    "df_test['entry_box'] = df_test.apply(lambda row: get_box(row['x_entry'], row['y_entry']) , axis=1)\n",
    "df_test['exit_box'] = df_test.apply(lambda row: get_box(row['x_exit'], row['y_exit']) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('df_train')\n",
    "df_test.to_pickle('df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.groupby('hash')\n",
    "df_list = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_group = df_test.groupby('hash')\n",
    "df_test_list = list(df_test_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "print(len(df_list))\n",
    "for index, sample in enumerate(df_list):\n",
    "    length = sample[1].shape[0]\n",
    "    count = 0\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['trajectory_id']  = row['trajectory_id']\n",
    "        if(count < length - 1):\n",
    "#             features['box_'+ str(row['entry_box'])]  = features.get('box_'+ str(row['entry_box']),0) + 1\n",
    "#             features['box_' + str(row['exit_box'])]  = features.get('box_'+ str(row['exit_box']),0) + 1\n",
    "            features['entry_box_'+ str(row['entry_box'])]  = features.get('entry_box_'+ str(row['entry_box']),0) + 1\n",
    "            features['exit_box_' + str(row['exit_box'])]  = features.get('exit_box_'+ str(row['exit_box']),0) + 1\n",
    "            features['duration_history']  = features.get('duration_history', 0) + row['duration']\n",
    "            features['distance_history']  = features.get('distance_history', 0) + row['distance']\n",
    "#             features['entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h')))] = features.get('entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['exit_time_'+ str(int(row['time_exit'] / np.timedelta64(1, 'h')))] = features.get('exit_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['box_duration_'+ str(row['entry_box'])]  = features.get('box_duration_'+ str(row['entry_box']),0) + row['duration']\n",
    "#             features['box_distance_'+ str(row['entry_box'])]  = features.get('box_distance'+ str(row['entry_box']),0) + row['distance']\n",
    "            \n",
    "        else:\n",
    "            features['l_entry']  = row['entry_box']\n",
    "#             features['l_exit']  = row['exit_box']\n",
    "            features['x_entry'] = row['x_entry']\n",
    "            features['y_entry'] = row['y_entry']\n",
    "            features['duration'] = row['duration']\n",
    "            features['city_distance'] = row['city_distance']\n",
    "            features['hour'] = row['hour']\n",
    "            features['label'] = row['label']\n",
    "        count = count + 1\n",
    "    features['duration_history'] = features.get('duration_history', 0) / length\n",
    "    features['distance_history'] = features.get('distance_history', 0) / length\n",
    "#     comp = new_train[new_train['hash'] == sample[0]]\n",
    "#     features['avg_azimuth'] = comp.avg_azimuth.mean()\n",
    "#     features['box_area'] = comp.box_area.mean()\n",
    "#     for index2, row in comp.iterrows():\n",
    "#         features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "#         features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "    dataset.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "print(len(df_test_list))\n",
    "for index, sample in enumerate(df_test_list):\n",
    "    length = sample[1].shape[0]\n",
    "    count = 0\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['trajectory_id']  = row['trajectory_id']\n",
    "        if(count < length - 1):\n",
    "#             features['box_'+ str(row['entry_box'])]  = features.get('box_'+ str(row['entry_box']),0) + 1\n",
    "#             features['box_' + str(row['exit_box'])]  = features.get('box_'+ str(row['exit_box']),0) + 1\n",
    "            features['entry_box_'+ str(row['entry_box'])]  = features.get('entry_box_'+ str(row['entry_box']),0) + 1\n",
    "            features['exit_box_' + str(row['exit_box'])]  = features.get('exit_box_'+ str(row['exit_box']),0) + 1\n",
    "            features['duration_history']  = features.get('duration_history', 0) + row['duration']\n",
    "            features['distance_history']  = features.get('distance_history', 0) + row['distance']\n",
    "#             features['entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h')))] = features.get('entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['exit_time_'+ str(int(row['time_exit'] / np.timedelta64(1, 'h')))] = features.get('exit_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['box_duration_'+ str(row['entry_box'])]  = features.get('box_duration_'+ str(row['entry_box']),0) + row['duration']\n",
    "#             features['box_distance_'+ str(row['entry_box'])]  = features.get('box_distance'+ str(row['entry_box']),0) + row['distance']\n",
    "        else:\n",
    "            features['l_entry']  = row['entry_box']\n",
    "#             features['l_exit']  = 0\n",
    "            features['x_entry'] = row['x_entry']\n",
    "            features['y_entry'] = row['y_entry']\n",
    "            features['duration'] = row['duration']\n",
    "            features['city_distance'] = row['city_distance']\n",
    "            features['hour'] = row['hour']\n",
    "            features['label'] = -1\n",
    "        count = count + 1\n",
    "    features['duration_history'] = features.get('duration_history', 0) / length\n",
    "    features['distance_history'] = features.get('distance_history', 0) / length\n",
    "#     comp = new_test[new_test['hash'] == sample[0]]\n",
    "#     features['avg_azimuth'] = comp.avg_azimuth.mean()\n",
    "#     features['box_area'] = comp.box_area.mean()\n",
    "#     for index2, row in comp.iterrows():\n",
    "#         features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "#         features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "#     if index % 100) == 0:\n",
    "#         print(index)\n",
    "    test_dataset.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(dataset).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = pd.DataFrame(test_dataset).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_df['box_5'] = 0.0\n",
    "# x_test_df['box_distance_5'] = 0.0\n",
    "# x_test_df['box_duration_5'] = 0.0\n",
    "x_test_df['entry_box_5'] = 0.0\n",
    "x_test_df['exit_box_5'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_df.shape, x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df.to_pickle('x_train_df')\n",
    "x_test_df.to_pickle('x_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_1 = x_train_df[['city_distance', 'y_entry', 'l_entry','x_entry','avg_trip_length_15','exit_box_36',\n",
    "                              'entry_box_36','duration','box_area','exit_box_37','avg_trip_length_14','entry_box_37',\n",
    "                              'hour','avg_trip_duration_15','avg_azimuth_15','distance_history','avg_trip_duration_14',\n",
    "                              'duration_history','exit_box_38','avg_azimuth_14', 'label','hash','trajectory_id']]\n",
    "testing_dataset_1 = x_test_df[['city_distance', 'y_entry', 'l_entry','x_entry','avg_trip_length_15','exit_box_36',\n",
    "                              'entry_box_36','duration','box_area','exit_box_37','avg_trip_length_14','entry_box_37',\n",
    "                              'hour','avg_trip_duration_15','avg_azimuth_15','distance_history','avg_trip_duration_14',\n",
    "                              'duration_history','exit_box_38','avg_azimuth_14', 'label','hash','trajectory_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = training_dataset_1.drop(['hash','trajectory_id'], axis=1)\n",
    "testing_dataset = testing_dataset_1.drop(['hash','trajectory_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = x_train_df.drop(['hash','trajectory_id'], axis=1)\n",
    "testing_dataset = x_test_df.drop(['hash','trajectory_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = training_dataset.drop(['label'], axis=1).values\n",
    "y_1 = training_dataset['label'].values\n",
    "sc_1 = StandardScaler()\n",
    "x_1 = sc_1.fit_transform(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(x_1, y_1, test_size = 0.1, random_state = 0)\n",
    "clf_1 = RandomForestClassifier(n_jobs = -1, n_estimators = 1000, max_depth = 100, random_state=42)\n",
    "# clf_1 = GaussianNB()\n",
    "# clf_1 = AdaBoostClassifier(n_estimators=100)\n",
    "# clf_1 = SVC(gamma=2, C=1)\n",
    "# clf_1 = MLPClassifier(activation= 'relu',hidden_layer_sizes=(10,10,10))\n",
    "# clf_1 = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "# clf_1 = LogisticRegression(penalty ='l2',dual = True)\n",
    "# clf_1 = DecisionTreeClassifier(max_depth=1000)\n",
    "# clf_1 = KNeighborsClassifier(3)\n",
    "clf_1.fit(xTrain, yTrain)\n",
    "yPred = clf_1.predict(xTest)\n",
    "print(classification_report(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_dataset.drop(['label'], axis=1).columns.values\n",
    "importances = clf_1.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "# for f in range(xTrain.shape[1]):\n",
    "#     print(f + 1, importances[f], features[f])\n",
    "for f in range(xTrain.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]), features[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df['label'] =  clf_1.predict(sc_1.fit_transform(testing_dataset.drop(['label'], axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df['label'] = x_test_df.apply(lambda row: 0 \n",
    "                                 if ((row['duration'] == 0.0) &\n",
    "                                     ~(((row['x_entry'] >= 3750901.5068) &\n",
    "                                                               (row['x_entry'] <= 3770901.5068)) &\n",
    "                                       ((row['y_entry'] >= -19268905.6133) &\n",
    "                                        (row['y_entry'] <= -19208905.6133))))\n",
    "                                 else row['label'], axis=1)\n",
    "x_test_df['label'] = x_test_df.apply(lambda row: 1\n",
    "                                 if ((row['duration'] == 0.0) &\n",
    "                                     (((row['x_entry'] >= 3750901.5068) &\n",
    "                                                               (row['x_entry'] <= 3770901.5068)) &\n",
    "                                       ((row['y_entry'] >= -19268905.6133) &\n",
    "                                        (row['y_entry'] <= -19208905.6133))))\n",
    "                                 else row['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df.sort_values('trajectory_id',ascending=True)[['trajectory_id','label']].to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_not_in_city = x_test_df[~(((x_test_df['x_entry'] >= 3750901.5068) &\n",
    "         (x_test_df['x_entry'] <= 3770901.5068)) & ((x_test_df['y_entry'] >= -19268905.6133) &\n",
    "         (x_test_df['y_entry'] <= -19208905.6133)))]\n",
    "test_start_in_city = x_test_df[((x_test_df['x_entry'] >= 3750901.5068) &\n",
    "         (x_test_df['x_entry'] <= 3770901.5068)) & ((x_test_df['y_entry'] >= -19268905.6133) &\n",
    "         (x_test_df['y_entry'] <= -19208905.6133))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_not_in_city.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_not_in_city.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_in_city.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_in_city.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_row(row):\n",
    "    rect = patches.Rectangle((3750901.5068,-19208905.6133), (3770901.5068 - 3750901.5068),\n",
    "                             (- 19268905.6133 + 19208905.6133),\n",
    "                             linewidth=1,edgecolor='g',fill = False, label = 'city center')\n",
    "    city = plt.gca().add_patch(rect)\n",
    "    arrows = plt.plot([row['x_entry'], row['x_exit']], [row['y_entry'], row['y_exit']], color = 'b')\n",
    "    entries = plt.scatter(row['x_entry'],row['y_entry'], label='Entry point', color = 'b')\n",
    "    exits = plt.scatter(row['x_exit'],row['y_exit'], label='Exit point', color = 'r')\n",
    "    plt.legend(handles=[city,entries, exits])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'x_exit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4380\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4381\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4382\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-f21e94e8e791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-105-c77700cf40dc>\u001b[0m in \u001b[0;36mplot_row\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      4\u001b[0m                              linewidth=1,edgecolor='g',fill = False, label = 'city center')\n\u001b[0;32m      5\u001b[0m     \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_patch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0marrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_entry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_exit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_entry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_exit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_entry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_entry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Entry point'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mexits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_exit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_exit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Exit point'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4387\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4388\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4389\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4390\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4391\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4373\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4375\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4376\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'x_exit'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_row(x_test_df.iloc[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_row(df_test[df_test['hash'] == '726ca607cd4197a8e33eafc8de6862bf_23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.read_csv(\"data_avg.csv\")\n",
    "new_test = pd.read_csv(\"data_test_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = new_train.groupby('hash')\n",
    "new_train_df_list = list(new_train_df)\n",
    "new_test_df = new_test.groupby('hash')\n",
    "new_test_df_list = list(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_1 = []\n",
    "print(len(new_train_df_list))\n",
    "for index, sample in enumerate(new_train_df_list):\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "        features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "        features['avg_azimuth_'+ str(row['entry_hour'])]  = features.get('avg_azimuth_'+ str(row['entry_hour']),0) + row['avg_azimuth']\n",
    "    features['box_area'] = sample[1].box_area.mean()\n",
    "    train_dataset_1.append(features)\n",
    "    if index % 10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_1 = []\n",
    "print(len(new_test_df_list))\n",
    "for index, sample in enumerate(new_test_df_list):\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "        features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "        features['avg_azimuth_'+ str(row['entry_hour'])]  = features.get('avg_azimuth_'+ str(row['entry_hour']),0) + row['avg_azimuth']\n",
    "#     features['avg_azimuth'] = sample[1].avg_azimuth.mean()\n",
    "    features['box_area'] = sample[1].box_area.mean()\n",
    "    test_dataset_1.append(features)\n",
    "    if index % 10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_1 = pd.DataFrame(train_dataset_1).fillna(0)\n",
    "x_test_df_1 = pd.DataFrame(test_dataset_1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_1 = x_train_df_1.sort_values('hash',ascending=True)\n",
    "x_test_df_1 = x_test_df_1.sort_values('hash',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_df.shape, x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_1.to_pickle('new_x_train_df')\n",
    "x_test_df_1.drop(['avg_azimuth'], axis=1).to_pickle('new_x_test_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = decomposition.PCA()\n",
    "# pca.fit(x_1)\n",
    "# plt.figure(1, figsize=(4, 3))\n",
    "# plt.clf()\n",
    "# plt.axes([.2, .2, .7, .7])\n",
    "# plt.plot(pca.explained_variance_, linewidth=2)\n",
    "# plt.axis('tight')\n",
    "# plt.xlabel('n_components')\n",
    "# plt.ylabel('explained_variance_')\n",
    "# x_1 = pca.transform(x_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
