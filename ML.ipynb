{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point, LinearRing, box\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('df_train')\n",
    "df_test = pd.read_pickle('df_test')\n",
    "x_train_df_1 = pd.read_pickle('new_x_train_df')\n",
    "x_test_df_1 = pd.read_pickle('new_x_test_df')\n",
    "x_train_df = pd.read_pickle('x_train_df_2')\n",
    "x_test_df = pd.read_pickle('x_test_df_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = x_train_df.sort_values('hash',ascending=True)\n",
    "x_test_df = x_test_df.sort_values('hash',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.merge(x_train_df, x_train_df_1, on='hash')\n",
    "x_test_df = pd.merge(x_test_df, x_test_df_1, on='hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134063, 171) (33515, 171)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_df.shape, x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x_entry = min(min(df_train.x_entry.describe()['min'], df_test.x_entry.describe()['min']),\n",
    "                  df_train.x_exit.describe()['min'])\n",
    "min_y_entry = min(min(df_train.y_entry.describe()['min'], df_test.y_entry.describe()['min']),\n",
    "                  df_train.y_exit.describe()['min'])\n",
    "max_x_entry = max(max(df_train.x_entry.describe()['max'], df_test.x_entry.describe()['max']),\n",
    "                  df_train.x_exit.describe()['max'])\n",
    "max_y_entry = max(max(df_train.y_entry.describe()['max'], df_test.y_entry.describe()['max']),\n",
    "                  df_train.y_exit.describe()['max'])\n",
    "print(min_x_entry, max_x_entry, min_y_entry, max_y_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map():\n",
    "    rect_all = patches.Rectangle((3740998.35481912, -19042656.658487003), (3777099.2656833767 - 3740998.35481912),\n",
    "                             (- 19382914.9809002 + 19042656.658487003),\n",
    "                             linewidth=1,edgecolor='g',fill = False,hatch = '\\\\\\\\\\\\', label = 'city')\n",
    "    city = plt.gca().add_patch(rect_all)\n",
    "    rect_city = patches.Rectangle((3750901.5068, -19208905.6133), (3770901.5068 - 3750901.5068),\n",
    "                             (- 19268905.6133 + 19208905.6133),\n",
    "                             linewidth=1,edgecolor='r',fill = False,hatch = '//////', label = 'city center')\n",
    "    city_center = plt.gca().add_patch(rect_city)\n",
    "    plt.legend(handles=[city, city_center])\n",
    "    plt.grid(True)\n",
    "#     plt.xlim(min_x_entry, max_x_entry)\n",
    "    plt.ylim(min_y_entry, max_y_entry)\n",
    "    plt.xlim(3740000, 3780000)\n",
    "    plt.ylim(-19000000, - 19400000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(x,y):\n",
    "    n1 = -1\n",
    "    n2 = -1\n",
    "    if(~np.isnan(x) and ~np.isnan(y)):\n",
    "        if(x >= 3740000.0000000000 and x < 3745000.0000000000):\n",
    "            n1 = 1\n",
    "        elif(x >= 3745000.0000000000 and x < 3750000.0000000000):\n",
    "            n1 = 2\n",
    "        elif(x >= 3750000.0000000000 and x < 3755000.0000000000):\n",
    "            n1 = 3\n",
    "        elif(x >= 3755000.0000000000 and x < 3760000.0000000000):\n",
    "            n1 = 4\n",
    "        elif(x >= 3760000.0000000000 and x < 3765000.0000000000):\n",
    "            n1 = 5\n",
    "        elif(x >= 3765000.0000000000 and x < 3770000.0000000000):\n",
    "            n1 = 6\n",
    "        elif(x >= 3770000.0000000000 and x < 3775000.0000000000):\n",
    "            n1 = 7\n",
    "        else:\n",
    "            n1 = 8\n",
    "\n",
    "        if(y >= -19400000.0000000000 and y < -19350000.0000000000):\n",
    "            n2 = 8\n",
    "        elif(y >= -19350000.0000000000 and y < -19300000.0000000000):\n",
    "            n2 = 7\n",
    "        elif(y >= -19300000.0000000000 and y < -19250000.0000000000):\n",
    "            n2 = 6\n",
    "        elif(y >= -19250000.0000000000 and y < -19200000.0000000000):\n",
    "            n2 = 5\n",
    "        elif(y >= -19200000.0000000000 and y < -19150000.0000000000):\n",
    "            n2 = 4\n",
    "        elif(y >= -19150000.0000000000 and y < -19100000.0000000000):\n",
    "            n2 = 3\n",
    "        elif(y >= -19100000.0000000000 and y < -19050000.0000000000):\n",
    "            n2 = 2\n",
    "        else:\n",
    "            n2 = 1\n",
    "    \n",
    "        return (n2-1)*8 + n1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['distance'] = df_test.apply(lambda row: Point(row['x_entry'],row['y_entry']).\n",
    "                                      distance(Point(row['x_exit'],row['y_exit'])) if ~np.isnan(row['x_exit'])\n",
    "                                     else np.nan, axis=1)\n",
    "df_test['velocity'] = df_test.apply(lambda row: (row['distance']/row['duration'])\n",
    "                                      if (row['duration']!= 0.0 and ~np.isnan(row['x_exit'])) else 0.0, axis=1)\n",
    "df_train['entry_box'] = df_train.apply(lambda row: get_box(row['x_entry'], row['y_entry']) , axis=1)\n",
    "df_train['exit_box'] = df_train.apply(lambda row: get_box(row['x_exit'], row['y_exit']) , axis=1)\n",
    "df_test['entry_box'] = df_test.apply(lambda row: get_box(row['x_entry'], row['y_entry']) , axis=1)\n",
    "df_test['exit_box'] = df_test.apply(lambda row: get_box(row['x_exit'], row['y_exit']) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('df_train')\n",
    "df_test.to_pickle('df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.groupby('hash')\n",
    "df_list = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_group = df_test.groupby('hash')\n",
    "df_test_list = list(df_test_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134063\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "print(len(df_list))\n",
    "for index, sample in enumerate(df_list):\n",
    "    length = sample[1].shape[0]\n",
    "    count = 0\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['trajectory_id']  = row['trajectory_id']\n",
    "        if(count < length - 1):\n",
    "#             features['box_'+ str(row['entry_box'])]  = features.get('box_'+ str(row['entry_box']),0) + 1\n",
    "#             features['box_' + str(row['exit_box'])]  = features.get('box_'+ str(row['exit_box']),0) + 1\n",
    "            features['entry_box_'+ str(row['entry_box'])]  = features.get('entry_box_'+ str(row['entry_box']),0) + 1\n",
    "            features['exit_box_' + str(row['exit_box'])]  = features.get('exit_box_'+ str(row['exit_box']),0) + 1\n",
    "            features['duration_history']  = features.get('duration_history', 0) + row['duration']\n",
    "            features['distance_history']  = features.get('distance_history', 0) + row['distance']\n",
    "#             features['entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h')))] = features.get('entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['exit_time_'+ str(int(row['time_exit'] / np.timedelta64(1, 'h')))] = features.get('exit_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['box_duration_'+ str(row['entry_box'])]  = features.get('box_duration_'+ str(row['entry_box']),0) + row['duration']\n",
    "#             features['box_distance_'+ str(row['entry_box'])]  = features.get('box_distance'+ str(row['entry_box']),0) + row['distance']\n",
    "            \n",
    "        else:\n",
    "            features['l_entry']  = row['entry_box']\n",
    "#             features['l_exit']  = row['exit_box']\n",
    "            features['x_entry'] = row['x_entry']\n",
    "            features['y_entry'] = row['y_entry']\n",
    "            features['duration'] = row['duration']\n",
    "            features['city_distance'] = row['city_distance']\n",
    "            features['hour'] = row['hour']\n",
    "            features['label'] = row['label']\n",
    "        count = count + 1\n",
    "    features['duration_history'] = features.get('duration_history', 0) / length\n",
    "    features['distance_history'] = features.get('distance_history', 0) / length\n",
    "#     comp = new_train[new_train['hash'] == sample[0]]\n",
    "#     features['avg_azimuth'] = comp.avg_azimuth.mean()\n",
    "#     features['box_area'] = comp.box_area.mean()\n",
    "#     for index2, row in comp.iterrows():\n",
    "#         features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "#         features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "    dataset.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33515\n"
     ]
    }
   ],
   "source": [
    "test_dataset = []\n",
    "print(len(df_test_list))\n",
    "for index, sample in enumerate(df_test_list):\n",
    "    length = sample[1].shape[0]\n",
    "    count = 0\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['trajectory_id']  = row['trajectory_id']\n",
    "        if(count < length - 1):\n",
    "#             features['box_'+ str(row['entry_box'])]  = features.get('box_'+ str(row['entry_box']),0) + 1\n",
    "#             features['box_' + str(row['exit_box'])]  = features.get('box_'+ str(row['exit_box']),0) + 1\n",
    "            features['entry_box_'+ str(row['entry_box'])]  = features.get('entry_box_'+ str(row['entry_box']),0) + 1\n",
    "            features['exit_box_' + str(row['exit_box'])]  = features.get('exit_box_'+ str(row['exit_box']),0) + 1\n",
    "            features['duration_history']  = features.get('duration_history', 0) + row['duration']\n",
    "            features['distance_history']  = features.get('distance_history', 0) + row['distance']\n",
    "#             features['entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h')))] = features.get('entry_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['exit_time_'+ str(int(row['time_exit'] / np.timedelta64(1, 'h')))] = features.get('exit_time_'+ str(int(row['time_entry'] / np.timedelta64(1, 'h'))),0) + 1\n",
    "#             features['box_duration_'+ str(row['entry_box'])]  = features.get('box_duration_'+ str(row['entry_box']),0) + row['duration']\n",
    "#             features['box_distance_'+ str(row['entry_box'])]  = features.get('box_distance'+ str(row['entry_box']),0) + row['distance']\n",
    "        else:\n",
    "            features['l_entry']  = row['entry_box']\n",
    "#             features['l_exit']  = 0\n",
    "            features['x_entry'] = row['x_entry']\n",
    "            features['y_entry'] = row['y_entry']\n",
    "            features['duration'] = row['duration']\n",
    "            features['city_distance'] = row['city_distance']\n",
    "            features['hour'] = row['hour']\n",
    "            features['label'] = -1\n",
    "        count = count + 1\n",
    "    features['duration_history'] = features.get('duration_history', 0) / length\n",
    "    features['distance_history'] = features.get('distance_history', 0) / length\n",
    "#     comp = new_test[new_test['hash'] == sample[0]]\n",
    "#     features['avg_azimuth'] = comp.avg_azimuth.mean()\n",
    "#     features['box_area'] = comp.box_area.mean()\n",
    "#     for index2, row in comp.iterrows():\n",
    "#         features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "#         features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "#     if index % 100) == 0:\n",
    "#         print(index)\n",
    "    test_dataset.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(dataset).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = pd.DataFrame(test_dataset).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_df['box_5'] = 0.0\n",
    "# x_test_df['box_distance_5'] = 0.0\n",
    "# x_test_df['box_duration_5'] = 0.0\n",
    "x_test_df['entry_box_5'] = 0.0\n",
    "x_test_df['exit_box_5'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134063, 155) (33515, 155)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_df.shape, x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df.to_pickle('x_train_df')\n",
    "x_test_df.to_pickle('x_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_1 = x_train_df[['city_distance', 'y_entry', 'l_entry','x_entry','avg_trip_length_15','exit_box_36',\n",
    "                              'entry_box_36','duration','box_area','exit_box_37','avg_trip_length_14','entry_box_37',\n",
    "                              'hour','avg_trip_duration_15','avg_azimuth_15','distance_history','avg_trip_duration_14',\n",
    "                              'duration_history','exit_box_38','avg_azimuth_14', 'label','hash','trajectory_id']]\n",
    "testing_dataset_1 = x_test_df[['city_distance', 'y_entry', 'l_entry','x_entry','avg_trip_length_15','exit_box_36',\n",
    "                              'entry_box_36','duration','box_area','exit_box_37','avg_trip_length_14','entry_box_37',\n",
    "                              'hour','avg_trip_duration_15','avg_azimuth_15','distance_history','avg_trip_duration_14',\n",
    "                              'duration_history','exit_box_38','avg_azimuth_14', 'label','hash','trajectory_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = training_dataset_1.drop(['hash','trajectory_id'], axis=1)\n",
    "testing_dataset = testing_dataset_1.drop(['hash','trajectory_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = x_train_df.drop(['hash','trajectory_id'], axis=1)\n",
    "testing_dataset = x_test_df.drop(['hash','trajectory_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = training_dataset.drop(['label'], axis=1).values\n",
    "y_1 = training_dataset['label'].values\n",
    "sc_1 = StandardScaler()\n",
    "x_1 = sc_1.fit_transform(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      9768\n",
      "           1       0.97      0.90      0.93      3639\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     13407\n",
      "   macro avg       0.97      0.94      0.95     13407\n",
      "weighted avg       0.96      0.96      0.96     13407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(x_1, y_1, test_size = 0.1, random_state = 0)\n",
    "clf_1 = RandomForestClassifier(n_jobs = -1, n_estimators = 1000, max_depth = 100, random_state=42)\n",
    "# clf_1 = GaussianNB()\n",
    "# clf_1 = AdaBoostClassifier(n_estimators=100)\n",
    "# clf_1 = SVC(gamma=2, C=1)\n",
    "# clf_1 = MLPClassifier(activation= 'relu',hidden_layer_sizes=(10,10,10))\n",
    "# clf_1 = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "# clf_1 = LogisticRegression(penalty ='l2',dual = True)\n",
    "# clf_1 = DecisionTreeClassifier(max_depth=1000)\n",
    "# clf_1 = KNeighborsClassifier(3)\n",
    "clf_1.fit(xTrain, yTrain)\n",
    "yPred = clf_1.predict(xTest)\n",
    "print(classification_report(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 0 (0.381288) city_distance\n",
      "2. feature 1 (0.127894) y_entry\n",
      "3. feature 2 (0.088126) l_entry\n",
      "4. feature 4 (0.062286) avg_trip_length_15\n",
      "5. feature 3 (0.046143) x_entry\n",
      "6. feature 5 (0.039422) exit_box_36\n",
      "7. feature 7 (0.037977) duration\n",
      "8. feature 10 (0.030948) avg_trip_length_14\n",
      "9. feature 6 (0.022795) entry_box_36\n",
      "10. feature 8 (0.022641) box_area\n",
      "11. feature 12 (0.020303) hour\n",
      "12. feature 14 (0.019030) avg_azimuth_15\n",
      "13. feature 9 (0.017474) exit_box_37\n",
      "14. feature 13 (0.017036) avg_trip_duration_15\n",
      "15. feature 11 (0.014019) entry_box_37\n",
      "16. feature 15 (0.012754) distance_history\n",
      "17. feature 16 (0.011091) avg_trip_duration_14\n",
      "18. feature 19 (0.011039) avg_azimuth_14\n",
      "19. feature 17 (0.010817) duration_history\n",
      "20. feature 18 (0.006916) exit_box_38\n"
     ]
    }
   ],
   "source": [
    "features = training_dataset.drop(['label'], axis=1).columns.values\n",
    "importances = clf_1.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "# for f in range(xTrain.shape[1]):\n",
    "#     print(f + 1, importances[f], features[f])\n",
    "for f in range(xTrain.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]), features[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df['label'] =  clf_1.predict(sc_1.fit_transform(testing_dataset.drop(['label'], axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df['label'] = x_test_df.apply(lambda row: 0 \n",
    "                                 if ((row['duration'] == 0.0) &\n",
    "                                     ~(((row['x_entry'] >= 3750901.5068) &\n",
    "                                                               (row['x_entry'] <= 3770901.5068)) &\n",
    "                                       ((row['y_entry'] >= -19268905.6133) &\n",
    "                                        (row['y_entry'] <= -19208905.6133))))\n",
    "                                 else row['label'], axis=1)\n",
    "x_test_df['label'] = x_test_df.apply(lambda row: 1\n",
    "                                 if ((row['duration'] == 0.0) &\n",
    "                                     (((row['x_entry'] >= 3750901.5068) &\n",
    "                                                               (row['x_entry'] <= 3770901.5068)) &\n",
    "                                       ((row['y_entry'] >= -19268905.6133) &\n",
    "                                        (row['y_entry'] <= -19208905.6133))))\n",
    "                                 else row['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25618\n",
       "1     7897\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df.sort_values('trajectory_id',ascending=True)[['trajectory_id','label']].to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_not_in_city = x_test_df[~(((x_test_df['x_entry'] >= 3750901.5068) &\n",
    "         (x_test_df['x_entry'] <= 3770901.5068)) & ((x_test_df['y_entry'] >= -19268905.6133) &\n",
    "         (x_test_df['y_entry'] <= -19208905.6133)))]\n",
    "test_start_in_city = x_test_df[((x_test_df['x_entry'] >= 3750901.5068) &\n",
    "         (x_test_df['x_entry'] <= 3770901.5068)) & ((x_test_df['y_entry'] >= -19268905.6133) &\n",
    "         (x_test_df['y_entry'] <= -19208905.6133))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23857\n",
       "1      114\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_start_not_in_city.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_not_in_city.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_in_city.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7804\n",
       "0    1740\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_start_in_city.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_row(row):\n",
    "    rect = patches.Rectangle((3750901.5068,-19208905.6133), (3770901.5068 - 3750901.5068),\n",
    "                             (- 19268905.6133 + 19208905.6133),\n",
    "                             linewidth=1,edgecolor='g',fill = False, label = 'city center')\n",
    "    city = plt.gca().add_patch(rect)\n",
    "    arrows = plt.plot([row['x_entry'], row['x_exit']], [row['y_entry'], row['y_exit']], color = 'b')\n",
    "    entries = plt.scatter(row['x_entry'],row['y_entry'], label='Entry point', color = 'b')\n",
    "    exits = plt.scatter(row['x_exit'],row['y_exit'], label='Exit point', color = 'r')\n",
    "    plt.legend(handles=[city,entries, exits])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_row(df_test[df_test['hash'] == '726ca607cd4197a8e33eafc8de6862bf_23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.read_csv(\"data_avg.csv\")\n",
    "new_test = pd.read_csv(\"data_test_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = new_train.groupby('hash')\n",
    "new_train_df_list = list(new_train_df)\n",
    "new_test_df = new_test.groupby('hash')\n",
    "new_test_df_list = list(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134063\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n"
     ]
    }
   ],
   "source": [
    "train_dataset_1 = []\n",
    "print(len(new_train_df_list))\n",
    "for index, sample in enumerate(new_train_df_list):\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "        features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "        features['avg_azimuth_'+ str(row['entry_hour'])]  = features.get('avg_azimuth_'+ str(row['entry_hour']),0) + row['avg_azimuth']\n",
    "    features['box_area'] = sample[1].box_area.mean()\n",
    "    train_dataset_1.append(features)\n",
    "    if index % 10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33515\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "test_dataset_1 = []\n",
    "print(len(new_test_df_list))\n",
    "for index, sample in enumerate(new_test_df_list):\n",
    "    features = {}\n",
    "    features['hash'] = sample[0]\n",
    "    for index1, row in sample[1].iterrows():\n",
    "        features['avg_trip_duration_'+ str(row['entry_hour'])]  = features.get('avg_trip_duration_'+ str(row['entry_hour']),0) + row['avg_trip_duration']\n",
    "        features['avg_trip_length_'+ str(row['entry_hour'])]  = features.get('avg_trip_length_'+ str(row['entry_hour']),0) + row['avg_trip_length']\n",
    "        features['avg_azimuth_'+ str(row['entry_hour'])]  = features.get('avg_azimuth_'+ str(row['entry_hour']),0) + row['avg_azimuth']\n",
    "#     features['avg_azimuth'] = sample[1].avg_azimuth.mean()\n",
    "    features['box_area'] = sample[1].box_area.mean()\n",
    "    test_dataset_1.append(features)\n",
    "    if index % 10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_1 = pd.DataFrame(train_dataset_1).fillna(0)\n",
    "x_test_df_1 = pd.DataFrame(test_dataset_1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_1 = x_train_df_1.sort_values('hash',ascending=True)\n",
    "x_test_df_1 = x_test_df_1.sort_values('hash',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134063, 119) (33515, 119)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_df.shape, x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_1.to_pickle('new_x_train_df')\n",
    "x_test_df_1.drop(['avg_azimuth'], axis=1).to_pickle('new_x_test_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = decomposition.PCA()\n",
    "# pca.fit(x_1)\n",
    "# plt.figure(1, figsize=(4, 3))\n",
    "# plt.clf()\n",
    "# plt.axes([.2, .2, .7, .7])\n",
    "# plt.plot(pca.explained_variance_, linewidth=2)\n",
    "# plt.axis('tight')\n",
    "# plt.xlabel('n_components')\n",
    "# plt.ylabel('explained_variance_')\n",
    "# x_1 = pca.transform(x_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
