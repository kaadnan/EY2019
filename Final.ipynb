{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point, LinearRing, box\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134063, 119) (33515, 119)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle('df_train')\n",
    "df_test = pd.read_pickle('df_test')\n",
    "x_train_df = pd.read_pickle('x_train_df_2')\n",
    "x_test_df = pd.read_pickle('x_test_df_2')\n",
    "\n",
    "# pick = ['hash','avg_azimuth_12', 'avg_azimuth_13', 'avg_azimuth_14', 'avg_azimuth_15','box_area',\n",
    "#        'avg_trip_duration_12', 'avg_trip_duration_13', 'avg_trip_duration_14', 'avg_trip_duration_15',\n",
    "#        'avg_trip_length_12',  'avg_trip_length_13', 'avg_trip_length_14', 'avg_trip_length_15']\n",
    "# x_train_df = pd.merge(x_train_df,  pd.read_pickle('new_x_train_df')[pick], on='hash')\n",
    "# x_test_df = pd.merge(x_test_df, pd.read_pickle('new_x_test_df')[pick], on='hash')\n",
    "\n",
    "# x_train_df = pd.merge(x_train_df, pd.read_csv(\"data_trip_city_buffer_train.csv\"), on='hash',how='left').fillna(0)\n",
    "\n",
    "\n",
    "print(x_train_df.shape, x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = x_train_df.drop(['hash','trajectory_id'], axis=1)\n",
    "testing_dataset = x_test_df.drop(['hash','trajectory_id'], axis=1)\n",
    "x_1 = training_dataset.drop(['label'], axis=1).values\n",
    "y_1 = training_dataset['label'].values\n",
    "sc_1 = StandardScaler()\n",
    "x_1 = sc_1.fit_transform(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=60, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(x_1, y_1, test_size = 0.0, random_state = 0)\n",
    "clf_1 = RandomForestClassifier(n_jobs = -1, criterion = 'entropy',n_estimators = 500, max_depth = 60,\n",
    "                               max_features = 'sqrt', random_state=42)\n",
    "# clf_1 = AdaBoostClassifier(n_estimators=100)\n",
    "# clf_1 = MLPClassifier(activation= 'relu',hidden_layer_sizes=(30,30,30))\n",
    "# clf_1 = DecisionTreeClassifier(max_depth=500)\n",
    "clf_1.fit(xTrain, yTrain)\n",
    "# yPred = clf_1.predict(xTest)\n",
    "# print(classification_report(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_dataset.drop(['label'], axis=1).columns.values\n",
    "importances = clf_1.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(xTrain.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]), features[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df['label'] =  clf_1.predict(sc_1.fit_transform(testing_dataset.drop(['label'], axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25258\n",
       "1     8257\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df['label'] = x_test_df.apply(lambda row: 0 \n",
    "                                 if ((row['duration'] == 0.0) &\n",
    "                                     ~(((row['x_entry'] >= 3750901.5068) &\n",
    "                                                               (row['x_entry'] <= 3770901.5068)) &\n",
    "                                       ((row['y_entry'] >= -19268905.6133) &\n",
    "                                        (row['y_entry'] <= -19208905.6133))))\n",
    "                                 else row['label'], axis=1)\n",
    "x_test_df['label'] = x_test_df.apply(lambda row: 1\n",
    "                                 if ((row['duration'] == 0.0) &\n",
    "                                     (((row['x_entry'] >= 3750901.5068) &\n",
    "                                                               (row['x_entry'] <= 3770901.5068)) &\n",
    "                                       ((row['y_entry'] >= -19268905.6133) &\n",
    "                                        (row['y_entry'] <= -19208905.6133))))\n",
    "                                 else row['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df.sort_values('trajectory_id',ascending=True)[['trajectory_id','label']].to_csv('output40.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
